# ğŸš— A3: Car Price Prediction (Classification)

### ğŸ‘¨â€ğŸ’» By Lu Htoo Kyaw (ST124956)

ğŸ”— **Live Website**: [https://st124956.ml.brain.cs.ait.ac.th/](https://st124956.ml.brain.cs.ait.ac.th/)

This project tackles car price prediction as a **classification problem** using **Multinomial Logistic Regression**, extending from previous regression-based implementations. It includes a full pipeline from data preprocessing and modeling to deployment using Docker and MLflow, with CI/CD integration through GitHub Actions.

---

## ğŸ“¦ Features

- ğŸ”¢ Converts `selling_price` into 4 discrete classes (0â€“3) using bucketing.
- ğŸ§® Custom implementation of **Logistic Regression** with:
  - Accuracy, Precision, Recall, F1-score (per class)
  - Macro and Weighted metrics
- ğŸ§ª Comparison with Scikit-learnâ€™s `classification_report`
- ğŸ§° Optional **Ridge (L2) Regularization**
- ğŸ“ˆ Tracked training with **MLflow** (remote server)
- ğŸš€ Deployed Django web application
- âœ… CI/CD with **GitHub Actions**
- ğŸ³ Containerized via **Docker Compose**

---

## ğŸ§  Model Details

The model transforms the car price prediction into a 4-class classification task by dividing the prices into bins. A custom logistic regression model was implemented with optional Ridge regularization:


Manual implementation of classification metrics:
- **Accuracy**
- **Precision, Recall, F1-score (per class)**
- **Macro averaging**
- **Weighted averaging**

---

## ğŸ› ï¸ Installation & Usage

### ğŸ”§ 1. Clone the Repository

```bash
git clone https://github.com/luhtookyaw/a3-car-price-prediction.git
cd a3-car-price-prediction
```

### ğŸ 2. Install Python Packages (Local)
```bash
cd app
pip3 install -r requirements.txt
python3 manage.py runserver
```
### ğŸ³ Docker Deployment

Build from Scratch
```bash
cd app
docker compose up -d
```
Pull and Run (Prebuilt)
```bash
docker compose up -d
```
### ğŸ“Š MLflow Integration
* Tracking URI: https://mlflow.ml.brain.cs.ait.ac.th/
* Experiment Name: st124956-a3
* Model Name: st124956-a3-model
* Stage: Staging

Experiments are logged with:
* Accuracy and F1 scores
* Hyperparameter settings
* Regularization choice
* Trained models and metrics

### ğŸ” CI/CD Pipeline
#### CI/CD Overview:
* Unit Tests:
  * âœ… Checks if the model accepts valid input
  * âœ… Verifies the prediction output shape

* GitHub Actions:
  * Runs tests on every push
  * Deploys the application automatically if tests pass



